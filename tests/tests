import os
import sys
import shutil
import tempfile
import numpy as np
import logging
from mne import create_info
from mne.io import RawArray
from mne.export import export_raw
from mne.io.eeglab.eeglab import read_raw_eeglab

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Add the src directory to the Python path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.modules.data_clean import clean_dataset  # Import after updating the path

def create_test_dataset(base_dir: str):
    """Create a test dataset with fake .set files.

    Parameters:
    - base_dir (str): Base directory to create the test dataset.
    """
    groups = ["Alzheimer", "Control", "Frontotemporal"]
    subfolders = ["raw", "clean", "band_power_matrices"]

    # Create group folders and subfolders
    for group in groups:
        group_path = os.path.join(base_dir, group)
        for subfolder in subfolders:
            os.makedirs(os.path.join(group_path, subfolder), exist_ok=True)

        # Generate fake EEG data and save as .set
        for i in range(2):  # Create 2 fake files per group
            n_channels = 19
            sfreq = 100  # Sampling frequency
            data = np.random.rand(n_channels, sfreq * 10)  # 10 seconds of data
            info = create_info(ch_names=[f"EEG{i}" for i in range(n_channels)], sfreq=sfreq, ch_types="eeg")
            raw = RawArray(data, info)

            file_name = f"{group[0].lower()}_test{i}.set"
            file_path = os.path.join(group_path, "raw", file_name)

            # Save the raw data as a .set file (EEGLAB format)
            export_raw(file_path, raw, fmt="eeglab")
            logger.info(f"Created test file: {file_path}")

def test_clean_dataset():
    """Test the clean_dataset function for correctness and robustness."""
    temp_dir = tempfile.mkdtemp()
    logger.info(f"Temporary test directory created at: {temp_dir}")

    try:
        # Step 1: Create a fake dataset
        create_test_dataset(temp_dir)

        # Step 2: Validate raw files
        for group in ["Alzheimer", "Control", "Frontotemporal"]:
            raw_dir = os.path.join(temp_dir, group, "raw")
            raw_files = [f for f in os.listdir(raw_dir) if f.endswith(".set")]
            assert len(raw_files) > 0, f"No raw files found in {raw_dir}!"
            logger.info(f"Raw files in {raw_dir}: {raw_files}")

        # Step 3: Run clean_dataset
        logger.info("Running clean_dataset...")
        clean_dataset(temp_dir)

        # Step 4: Validate cleaned files
        for group in ["Alzheimer", "Control", "Frontotemporal"]:
            clean_dir = os.path.join(temp_dir, group, "clean")
            cleaned_files = [f for f in os.listdir(clean_dir) if f.endswith("_cleaned.set")]
            assert len(cleaned_files) > 0, f"No cleaned files found in {clean_dir}!"
            logger.info(f"Cleaned files in {clean_dir}: {cleaned_files}")

            # Additional checks on cleaned files
            for cleaned_file in cleaned_files:
                cleaned_path = os.path.join(clean_dir, cleaned_file)
                raw_cleaned = read_raw_eeglab(cleaned_path, preload=False)
                assert raw_cleaned.info['sfreq'] == 100, f"Unexpected sampling frequency in {cleaned_file}"
                assert len(raw_cleaned.ch_names) == 19, f"Channel count mismatch in {cleaned_file}"
                logger.info(f"Validated cleaned file: {cleaned_path}")

    except Exception as e:
        logger.error(f"Test failed: {e}", exc_info=True)
    finally:
        # Clean up temporary directory
        shutil.rmtree(temp_dir)
        logger.info(f"Temporary test directory at {temp_dir} deleted.")

# Run the test
if __name__ == "__main__":
    test_clean_dataset()
